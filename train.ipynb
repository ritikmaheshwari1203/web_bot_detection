{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:\n",
      "Human: 35\n",
      "Bot: 35\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        15\n",
      "           1       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.90      0.90      0.90        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        15\n",
      "           1       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.80      0.80      0.80        30\n",
      "weighted avg       0.80      0.80      0.80        30\n",
      "\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        15\n",
      "           1       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.87      0.87      0.87        30\n",
      "weighted avg       0.87      0.87      0.87        30\n",
      "\n",
      "\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        15\n",
      "           1       0.76      0.87      0.81        15\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.81      0.80      0.80        30\n",
      "weighted avg       0.81      0.80      0.80        30\n",
      "\n",
      "All graphs have been saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (classification_report, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----------------------\n",
    "# File paths for logs and annotations\n",
    "# ----------------------\n",
    "bot_log_file = 'web_bot_detection_dataset/phase1/data/web_logs/bots/access_moderate_bots.log'\n",
    "human_log_file_1 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_1.log'\n",
    "human_log_file_2 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_2.log'\n",
    "human_log_file_3 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_3.log'\n",
    "human_log_file_4 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_4.log'\n",
    "human_log_file_5 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_5.log'\n",
    "\n",
    "train_annotation_file = 'web_bot_detection_dataset/phase1/annotations/humans_and_moderate_bots/train'\n",
    "test_annotation_file  = 'web_bot_detection_dataset/phase1/annotations/humans_and_moderate_bots/test'\n",
    "\n",
    "# ----------------------\n",
    "# Initialize session_features dictionary\n",
    "# ----------------------\n",
    "# We also store timestamps, HTML requests count, list of depths, and page request counts.\n",
    "session_features = defaultdict(lambda: {\n",
    "    'total_requests': 0,\n",
    "    'total_bytes': 0,\n",
    "    'GET': 0,\n",
    "    'POST': 0,\n",
    "    'http_3xx': 0,\n",
    "    'http_4xx': 0,\n",
    "    'image_requests': 0,\n",
    "    'html_requests': 0,\n",
    "    'depths': [],\n",
    "    'page_requests': {},\n",
    "    'timestamps': []\n",
    "})\n",
    "\n",
    "# ----------------------\n",
    "# Regular expressions for parsing and resource type matching.\n",
    "# ----------------------\n",
    "log_pattern = re.compile(\n",
    "    r'- - \\[(.*?)\\]\\s+\"(\\w+)\\s+([^\"]+)\\s+HTTP/[\\d.]+\"\\s+(\\d{3})\\s+(\\d+)\\s+\"([^\"]+)\"\\s+([^\\s]+)\\s+\"([^\"]+)\"'\n",
    ")\n",
    "image_pattern = re.compile(r'\\.(jpg|jpeg|png|gif|ico)$', re.IGNORECASE)\n",
    "css_pattern   = re.compile(r'\\.css$', re.IGNORECASE)\n",
    "js_pattern    = re.compile(r'\\.js$', re.IGNORECASE)\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"Process a log file and update session_features.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = log_pattern.match(line)\n",
    "            if match:\n",
    "                timestamp_str = match.group(1)\n",
    "                try:\n",
    "                    timestamp = datetime.strptime(timestamp_str, \"%d/%b/%Y:%H:%M:%S %z\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "                method = match.group(2)\n",
    "                url = match.group(3)\n",
    "                status = int(match.group(4))\n",
    "                bytes_count = int(match.group(5))\n",
    "                session_id = match.group(7)\n",
    "                if session_id == \"-\":\n",
    "                    continue\n",
    "                feat = session_features[session_id]\n",
    "                feat['total_requests'] += 1\n",
    "                feat['total_bytes'] += bytes_count\n",
    "                if method in ['GET', 'POST']:\n",
    "                    feat[method] += 1\n",
    "                if 300 <= status < 400:\n",
    "                    feat['http_3xx'] += 1\n",
    "                if 400 <= status < 500:\n",
    "                    feat['http_4xx'] += 1\n",
    "                if image_pattern.search(url):\n",
    "                    feat['image_requests'] += 1\n",
    "                # Heuristic: if not CSS, JS, or image, treat as HTML.\n",
    "                if not (css_pattern.search(url) or js_pattern.search(url) or image_pattern.search(url)):\n",
    "                    feat['html_requests'] += 1\n",
    "                depth = len(url.strip().split('/')) - 1\n",
    "                feat['depths'].append(depth)\n",
    "                feat['page_requests'][url] = feat['page_requests'].get(url, 0) + 1\n",
    "                feat['timestamps'].append(timestamp)\n",
    "\n",
    "# Process all log files.\n",
    "process_log_file(bot_log_file)\n",
    "process_log_file(human_log_file_1)\n",
    "process_log_file(human_log_file_2)\n",
    "process_log_file(human_log_file_3)\n",
    "process_log_file(human_log_file_4)\n",
    "process_log_file(human_log_file_5)\n",
    "\n",
    "# ----------------------\n",
    "# Compute derived features.\n",
    "# ----------------------\n",
    "SEQUENTIAL_THRESHOLD = 2.0  # seconds\n",
    "\n",
    "for session_id, feat in session_features.items():\n",
    "    # Image Requests Percent.\n",
    "    feat['image_requests_percent'] = (feat['image_requests'] / feat['total_requests'] * 100\n",
    "                                        if feat['total_requests'] > 0 else 0)\n",
    "    # HTML-to-Image Ratio.\n",
    "    feat['html_to_image_ratio'] = (feat['html_requests'] / feat['image_requests']\n",
    "                                    if feat['image_requests'] > 0 else feat['html_requests'])\n",
    "    # Depth Standard Deviation.\n",
    "    feat['depth_std'] = np.std(feat['depths']) if feat['depths'] else 0\n",
    "    # Max Requests Per Page.\n",
    "    feat['max_requests_per_page'] = max(feat['page_requests'].values()) if feat['page_requests'] else 0\n",
    "    \n",
    "    # Timing-based features.\n",
    "    timestamps = sorted(feat['timestamps'])\n",
    "    if timestamps:\n",
    "        session_duration = (timestamps[-1] - timestamps[0]).total_seconds()\n",
    "    else:\n",
    "        session_duration = 0\n",
    "    feat['session_duration'] = session_duration\n",
    "    if len(timestamps) > 1:\n",
    "        diffs = [(timestamps[i+1] - timestamps[i]).total_seconds() for i in range(len(timestamps)-1)]\n",
    "        feat['inter_request_avg'] = np.mean(diffs)\n",
    "        sequential_count = sum(1 for diff in diffs if diff < SEQUENTIAL_THRESHOLD)\n",
    "        feat['sequential_req_percent'] = (sequential_count / len(diffs)) * 100\n",
    "    else:\n",
    "        feat['inter_request_avg'] = 0\n",
    "        feat['sequential_req_percent'] = 0\n",
    "    # Browsing Speed.\n",
    "    feat['browsing_speed'] = (feat['total_requests'] / session_duration\n",
    "                              if session_duration > 0 else feat['total_requests'])\n",
    "\n",
    "# ----------------------\n",
    "# Convert session_features to DataFrame.\n",
    "# ----------------------\n",
    "df_features = pd.DataFrame.from_dict(session_features, orient='index')\n",
    "df_features.index.name = 'session_id'\n",
    "df_features.reset_index(inplace=True)\n",
    "\n",
    "def read_annotation(file_path):\n",
    "    \"\"\"Read an annotation file with session_id and label into a DataFrame.\"\"\"\n",
    "    annotations = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                session_id, label = parts\n",
    "                annotations.append({'session_id': session_id.strip(), 'label': label.strip().lower()})\n",
    "    return pd.DataFrame(annotations)\n",
    "\n",
    "df_train_annot = read_annotation(train_annotation_file)\n",
    "df_test_annot  = read_annotation(test_annotation_file)\n",
    "\n",
    "# ----------------------\n",
    "# Merge features with annotations using concat.\n",
    "# ----------------------\n",
    "df_features.set_index('session_id', inplace=True)\n",
    "df_train_annot.set_index('session_id', inplace=True)\n",
    "df_test_annot.set_index('session_id', inplace=True)\n",
    "df_train = pd.concat([df_features, df_train_annot], axis=1, join='inner').reset_index()\n",
    "df_test  = pd.concat([df_features, df_test_annot], axis=1, join='inner').reset_index()\n",
    "\n",
    "# Map labels: 'human' -> 0, 'moderate_bot'/'bot' -> 1.\n",
    "label_map = {'human': 0, 'moderate_bot': 1, 'bot': 1}\n",
    "df_train['label'] = df_train['label'].map(label_map)\n",
    "df_test['label']  = df_test['label'].map(label_map)\n",
    "\n",
    "print(\"Training distribution:\")\n",
    "print(\"Human:\", df_train[df_train['label'] == 0].shape[0])\n",
    "print(\"Bot:\", df_train[df_train['label'] == 1].shape[0])\n",
    "\n",
    "# ----------------------\n",
    "# Define feature columns and normalize inputs.\n",
    "# ----------------------\n",
    "feature_cols = [\n",
    "    'total_requests', \n",
    "    'total_bytes', \n",
    "    'GET', \n",
    "    'POST', \n",
    "    'http_3xx', \n",
    "    'http_4xx', \n",
    "    'image_requests_percent',\n",
    "    'html_to_image_ratio',\n",
    "    'depth_std',\n",
    "    'max_requests_per_page',\n",
    "    'sequential_req_percent',\n",
    "    'browsing_speed',\n",
    "    'session_duration',\n",
    "    'inter_request_avg'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['label']\n",
    "X_test  = df_test[feature_cols]\n",
    "y_test  = df_test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# Train multiple classifiers.\n",
    "# ----------------------\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_prob = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix for each classifier.\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Human\", \"Bot\"], yticklabels=[\"Human\", \"Bot\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1/{name.replace(' ', '_').lower()}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot a bar chart comparing classifier metrics.\n",
    "\n",
    "# 1. Training Distribution.\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=\"label\", data=df_train)\n",
    "plt.xticks([0, 1], [\"Human\", \"Bot\"])\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Training Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1/training_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Feature Correlation Heatmap.\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df_train[feature_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1/feature_correlation_heatmap.png\")\n",
    "plt.close()\n",
    "# ----------------------\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "metric_values = {metric: [results[clf][metric] for clf in results] for metric in metrics}\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.2\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, metric_values[metric], width, label=metric.title())\n",
    "plt.xticks(x + width*1.5, list(classifiers.keys()))\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Classifier Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1/classifier_performance_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot ROC curves for classifiers that support probability estimates.\n",
    "# ----------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "for name in classifiers:\n",
    "    if results[name][\"y_prob\"] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, results[name][\"y_prob\"])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1/roc_curve_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Additional Graphs on Feature Distributions and Scatter Plots.\n",
    "# ----------------------\n",
    "# Feature distributions (raw values)\n",
    "features_to_plot = ['total_requests', 'session_duration', 'browsing_speed', 'inter_request_avg']\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df_train[feature], bins=20, kde=True)\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.title(f\"Distribution of {feature.replace('_', ' ').title()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1/{feature}_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Scatter Plot: Session Duration vs. Browsing Speed.\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=\"session_duration\", y=\"browsing_speed\", hue=\"label\", data=df_train, palette=\"Set1\")\n",
    "plt.xlabel(\"Session Duration (s)\")\n",
    "plt.ylabel(\"Browsing Speed (req/s)\")\n",
    "plt.title(\"Session Duration vs. Browsing Speed\")\n",
    "plt.legend(title=\"Label\", labels=[\"Human\", \"Bot\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1/session_duration_vs_browsing_speed.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"All graphs have been saved as PNG files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:\n",
      "Human: 35\n",
      "Bot: 35\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       1.00      0.67      0.80        15\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.88      0.83      0.83        30\n",
      "weighted avg       0.88      0.83      0.83        30\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67        15\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.64      0.63      0.63        30\n",
      "weighted avg       0.64      0.63      0.63        30\n",
      "\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        15\n",
      "           1       1.00      0.73      0.85        15\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.89      0.87      0.86        30\n",
      "weighted avg       0.89      0.87      0.86        30\n",
      "\n",
      "\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        15\n",
      "           1       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "All graphs have been saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (classification_report, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----------------------\n",
    "# File paths for logs and annotations\n",
    "# ----------------------\n",
    "bot_log_file = 'web_bot_detection_dataset/phase1/data/web_logs/bots/access_advanced_bots.log'\n",
    "human_log_file_1 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_1.log'\n",
    "human_log_file_2 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_2.log'\n",
    "human_log_file_3 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_3.log'\n",
    "human_log_file_4 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_4.log'\n",
    "human_log_file_5 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_5.log'\n",
    "\n",
    "train_annotation_file = 'web_bot_detection_dataset/phase1/annotations/humans_and_advanced_bots/train'\n",
    "test_annotation_file  = 'web_bot_detection_dataset/phase1/annotations/humans_and_advanced_bots/test'\n",
    "\n",
    "# ----------------------\n",
    "# Initialize session_features dictionary\n",
    "# ----------------------\n",
    "# We also store timestamps, HTML requests count, list of depths, and page request counts.\n",
    "session_features = defaultdict(lambda: {\n",
    "    'total_requests': 0,\n",
    "    'total_bytes': 0,\n",
    "    'GET': 0,\n",
    "    'POST': 0,\n",
    "    'http_3xx': 0,\n",
    "    'http_4xx': 0,\n",
    "    'image_requests': 0,\n",
    "    'html_requests': 0,\n",
    "    'depths': [],\n",
    "    'page_requests': {},\n",
    "    'timestamps': []\n",
    "})\n",
    "\n",
    "# ----------------------\n",
    "# Regular expressions for parsing and resource type matching.\n",
    "# ----------------------\n",
    "log_pattern = re.compile(\n",
    "    r'- - \\[(.*?)\\]\\s+\"(\\w+)\\s+([^\"]+)\\s+HTTP/[\\d.]+\"\\s+(\\d{3})\\s+(\\d+)\\s+\"([^\"]+)\"\\s+([^\\s]+)\\s+\"([^\"]+)\"'\n",
    ")\n",
    "image_pattern = re.compile(r'\\.(jpg|jpeg|png|gif|ico)$', re.IGNORECASE)\n",
    "css_pattern   = re.compile(r'\\.css$', re.IGNORECASE)\n",
    "js_pattern    = re.compile(r'\\.js$', re.IGNORECASE)\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"Process a log file and update session_features.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = log_pattern.match(line)\n",
    "            if match:\n",
    "                timestamp_str = match.group(1)\n",
    "                try:\n",
    "                    timestamp = datetime.strptime(timestamp_str, \"%d/%b/%Y:%H:%M:%S %z\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "                method = match.group(2)\n",
    "                url = match.group(3)\n",
    "                status = int(match.group(4))\n",
    "                bytes_count = int(match.group(5))\n",
    "                session_id = match.group(7)\n",
    "                if session_id == \"-\":\n",
    "                    continue\n",
    "                feat = session_features[session_id]\n",
    "                feat['total_requests'] += 1\n",
    "                feat['total_bytes'] += bytes_count\n",
    "                if method in ['GET', 'POST']:\n",
    "                    feat[method] += 1\n",
    "                if 300 <= status < 400:\n",
    "                    feat['http_3xx'] += 1\n",
    "                if 400 <= status < 500:\n",
    "                    feat['http_4xx'] += 1\n",
    "                if image_pattern.search(url):\n",
    "                    feat['image_requests'] += 1\n",
    "                # Heuristic: if not CSS, JS, or image, treat as HTML.\n",
    "                if not (css_pattern.search(url) or js_pattern.search(url) or image_pattern.search(url)):\n",
    "                    feat['html_requests'] += 1\n",
    "                depth = len(url.strip().split('/')) - 1\n",
    "                feat['depths'].append(depth)\n",
    "                feat['page_requests'][url] = feat['page_requests'].get(url, 0) + 1\n",
    "                feat['timestamps'].append(timestamp)\n",
    "\n",
    "# Process all log files.\n",
    "process_log_file(bot_log_file)\n",
    "process_log_file(human_log_file_1)\n",
    "process_log_file(human_log_file_2)\n",
    "process_log_file(human_log_file_3)\n",
    "process_log_file(human_log_file_4)\n",
    "process_log_file(human_log_file_5)\n",
    "\n",
    "# ----------------------\n",
    "# Compute derived features.\n",
    "# ----------------------\n",
    "SEQUENTIAL_THRESHOLD = 2.0  # seconds\n",
    "\n",
    "for session_id, feat in session_features.items():\n",
    "    # Image Requests Percent.\n",
    "    feat['image_requests_percent'] = (feat['image_requests'] / feat['total_requests'] * 100\n",
    "                                        if feat['total_requests'] > 0 else 0)\n",
    "    # HTML-to-Image Ratio.\n",
    "    feat['html_to_image_ratio'] = (feat['html_requests'] / feat['image_requests']\n",
    "                                    if feat['image_requests'] > 0 else feat['html_requests'])\n",
    "    # Depth Standard Deviation.\n",
    "    feat['depth_std'] = np.std(feat['depths']) if feat['depths'] else 0\n",
    "    # Max Requests Per Page.\n",
    "    feat['max_requests_per_page'] = max(feat['page_requests'].values()) if feat['page_requests'] else 0\n",
    "    \n",
    "    # Timing-based features.\n",
    "    timestamps = sorted(feat['timestamps'])\n",
    "    if timestamps:\n",
    "        session_duration = (timestamps[-1] - timestamps[0]).total_seconds()\n",
    "    else:\n",
    "        session_duration = 0\n",
    "    feat['session_duration'] = session_duration\n",
    "    if len(timestamps) > 1:\n",
    "        diffs = [(timestamps[i+1] - timestamps[i]).total_seconds() for i in range(len(timestamps)-1)]\n",
    "        feat['inter_request_avg'] = np.mean(diffs)\n",
    "        sequential_count = sum(1 for diff in diffs if diff < SEQUENTIAL_THRESHOLD)\n",
    "        feat['sequential_req_percent'] = (sequential_count / len(diffs)) * 100\n",
    "    else:\n",
    "        feat['inter_request_avg'] = 0\n",
    "        feat['sequential_req_percent'] = 0\n",
    "    # Browsing Speed.\n",
    "    feat['browsing_speed'] = (feat['total_requests'] / session_duration\n",
    "                              if session_duration > 0 else feat['total_requests'])\n",
    "\n",
    "# ----------------------\n",
    "# Convert session_features to DataFrame.\n",
    "# ----------------------\n",
    "df_features = pd.DataFrame.from_dict(session_features, orient='index')\n",
    "df_features.index.name = 'session_id'\n",
    "df_features.reset_index(inplace=True)\n",
    "\n",
    "def read_annotation(file_path):\n",
    "    \"\"\"Read an annotation file with session_id and label into a DataFrame.\"\"\"\n",
    "    annotations = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                session_id, label = parts\n",
    "                annotations.append({'session_id': session_id.strip(), 'label': label.strip().lower()})\n",
    "    return pd.DataFrame(annotations)\n",
    "\n",
    "df_train_annot = read_annotation(train_annotation_file)\n",
    "df_test_annot  = read_annotation(test_annotation_file)\n",
    "\n",
    "# ----------------------\n",
    "# Merge features with annotations using concat.\n",
    "# ----------------------\n",
    "df_features.set_index('session_id', inplace=True)\n",
    "df_train_annot.set_index('session_id', inplace=True)\n",
    "df_test_annot.set_index('session_id', inplace=True)\n",
    "df_train = pd.concat([df_features, df_train_annot], axis=1, join='inner').reset_index()\n",
    "df_test  = pd.concat([df_features, df_test_annot], axis=1, join='inner').reset_index()\n",
    "\n",
    "# Map labels: 'human' -> 0, 'moderate_bot'/'bot' -> 1.\n",
    "label_map = {'human': 0, 'moderate_bot': 1, 'bot': 1, 'advanced_bot': 1}\n",
    "df_train['label'] = df_train['label'].map(label_map)\n",
    "df_test['label']  = df_test['label'].map(label_map)\n",
    "\n",
    "print(\"Training distribution:\")\n",
    "print(\"Human:\", df_train[df_train['label'] == 0].shape[0])\n",
    "print(\"Bot:\", df_train[df_train['label'] == 1].shape[0])\n",
    "\n",
    "# ----------------------\n",
    "# Define feature columns and normalize inputs.\n",
    "# ----------------------\n",
    "feature_cols = [\n",
    "    'total_requests', \n",
    "    'total_bytes', \n",
    "    'GET', \n",
    "    'POST', \n",
    "    'http_3xx', \n",
    "    'http_4xx', \n",
    "    'image_requests_percent',\n",
    "    'html_to_image_ratio',\n",
    "    'depth_std',\n",
    "    'max_requests_per_page',\n",
    "    'sequential_req_percent',\n",
    "    'browsing_speed',\n",
    "    'session_duration',\n",
    "    'inter_request_avg'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['label']\n",
    "X_test  = df_test[feature_cols]\n",
    "y_test  = df_test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# Train multiple classifiers.\n",
    "# ----------------------\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_prob = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix for each classifier.\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Human\", \"Bot\"], yticklabels=[\"Human\", \"Bot\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1_with_advance_bot/{name.replace(' ', '_').lower()}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot a bar chart comparing classifier metrics.\n",
    "\n",
    "# 1. Training Distribution.\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=\"label\", data=df_train)\n",
    "plt.xticks([0, 1], [\"Human\", \"Bot\"])\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Training Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/training_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Feature Correlation Heatmap.\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df_train[feature_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/feature_correlation_heatmap.png\")\n",
    "plt.close()\n",
    "# ----------------------\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "metric_values = {metric: [results[clf][metric] for clf in results] for metric in metrics}\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.2\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, metric_values[metric], width, label=metric.title())\n",
    "plt.xticks(x + width*1.5, list(classifiers.keys()))\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Classifier Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/classifier_performance_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot ROC curves for classifiers that support probability estimates.\n",
    "# ----------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "for name in classifiers:\n",
    "    if results[name][\"y_prob\"] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, results[name][\"y_prob\"])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/roc_curve_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Additional Graphs on Feature Distributions and Scatter Plots.\n",
    "# ----------------------\n",
    "# Feature distributions (raw values)\n",
    "features_to_plot = ['total_requests', 'session_duration', 'browsing_speed', 'inter_request_avg']\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df_train[feature], bins=20, kde=True)\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.title(f\"Distribution of {feature.replace('_', ' ').title()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1_with_advance_bot/{feature}_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Scatter Plot: Session Duration vs. Browsing Speed.\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=\"session_duration\", y=\"browsing_speed\", hue=\"label\", data=df_train, palette=\"Set1\")\n",
    "plt.xlabel(\"Session Duration (s)\")\n",
    "plt.ylabel(\"Browsing Speed (req/s)\")\n",
    "plt.title(\"Session Duration vs. Browsing Speed\")\n",
    "plt.legend(title=\"Label\", labels=[\"Human\", \"Bot\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/session_duration_vs_browsing_speed.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"All graphs have been saved as PNG files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:\n",
      "Human: 35\n",
      "Bot: 35\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       1.00      0.67      0.80        15\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.88      0.83      0.83        30\n",
      "weighted avg       0.88      0.83      0.83        30\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67        15\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.64      0.63      0.63        30\n",
      "weighted avg       0.64      0.63      0.63        30\n",
      "\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        15\n",
      "           1       1.00      0.73      0.85        15\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.89      0.87      0.86        30\n",
      "weighted avg       0.89      0.87      0.86        30\n",
      "\n",
      "\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        15\n",
      "           1       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_test_auc = 0.73333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\bot_detection\\env\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TabNet Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        15\n",
      "           1       0.73      0.73      0.73        15\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.73      0.73      0.73        30\n",
      "weighted avg       0.73      0.73      0.73        30\n",
      "\n",
      "All graphs have been saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (classification_report, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For TabNet\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# ----------------------\n",
    "# File paths for logs and annotations\n",
    "# ----------------------\n",
    "bot_log_file = 'web_bot_detection_dataset/phase1/data/web_logs/bots/access_advanced_bots.log'\n",
    "human_log_file_1 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_1.log'\n",
    "human_log_file_2 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_2.log'\n",
    "human_log_file_3 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_3.log'\n",
    "human_log_file_4 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_4.log'\n",
    "human_log_file_5 = 'web_bot_detection_dataset/phase1/data/web_logs/humans/access_5.log'\n",
    "\n",
    "train_annotation_file = 'web_bot_detection_dataset/phase1/annotations/humans_and_advanced_bots/train'\n",
    "test_annotation_file  = 'web_bot_detection_dataset/phase1/annotations/humans_and_advanced_bots/test'\n",
    "\n",
    "# ----------------------\n",
    "# Initialize session_features dictionary\n",
    "# ----------------------\n",
    "# We also store timestamps, HTML requests count, list of depths, and page request counts.\n",
    "session_features = defaultdict(lambda: {\n",
    "    'total_requests': 0,\n",
    "    'total_bytes': 0,\n",
    "    'GET': 0,\n",
    "    'POST': 0,\n",
    "    'http_3xx': 0,\n",
    "    'http_4xx': 0,\n",
    "    'image_requests': 0,\n",
    "    'html_requests': 0,\n",
    "    'depths': [],\n",
    "    'page_requests': {},\n",
    "    'timestamps': []\n",
    "})\n",
    "\n",
    "# ----------------------\n",
    "# Regular expressions for parsing and resource type matching.\n",
    "# ----------------------\n",
    "log_pattern = re.compile(\n",
    "    r'- - \\[(.*?)\\]\\s+\"(\\w+)\\s+([^\"]+)\\s+HTTP/[\\d.]+\"\\s+(\\d{3})\\s+(\\d+)\\s+\"([^\"]+)\"\\s+([^\\s]+)\\s+\"([^\"]+)\"'\n",
    ")\n",
    "image_pattern = re.compile(r'\\.(jpg|jpeg|png|gif|ico)$', re.IGNORECASE)\n",
    "css_pattern   = re.compile(r'\\.css$', re.IGNORECASE)\n",
    "js_pattern    = re.compile(r'\\.js$', re.IGNORECASE)\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    \"\"\"Process a log file and update session_features.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = log_pattern.match(line)\n",
    "            if match:\n",
    "                timestamp_str = match.group(1)\n",
    "                try:\n",
    "                    timestamp = datetime.strptime(timestamp_str, \"%d/%b/%Y:%H:%M:%S %z\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "                method = match.group(2)\n",
    "                url = match.group(3)\n",
    "                status = int(match.group(4))\n",
    "                bytes_count = int(match.group(5))\n",
    "                session_id = match.group(7)\n",
    "                if session_id == \"-\":\n",
    "                    continue\n",
    "                feat = session_features[session_id]\n",
    "                feat['total_requests'] += 1\n",
    "                feat['total_bytes'] += bytes_count\n",
    "                if method in ['GET', 'POST']:\n",
    "                    feat[method] += 1\n",
    "                if 300 <= status < 400:\n",
    "                    feat['http_3xx'] += 1\n",
    "                if 400 <= status < 500:\n",
    "                    feat['http_4xx'] += 1\n",
    "                if image_pattern.search(url):\n",
    "                    feat['image_requests'] += 1\n",
    "                # Heuristic: if not CSS, JS, or image, treat as HTML.\n",
    "                if not (css_pattern.search(url) or js_pattern.search(url) or image_pattern.search(url)):\n",
    "                    feat['html_requests'] += 1\n",
    "                depth = len(url.strip().split('/')) - 1\n",
    "                feat['depths'].append(depth)\n",
    "                feat['page_requests'][url] = feat['page_requests'].get(url, 0) + 1\n",
    "                feat['timestamps'].append(timestamp)\n",
    "\n",
    "# Process all log files.\n",
    "process_log_file(bot_log_file)\n",
    "process_log_file(human_log_file_1)\n",
    "process_log_file(human_log_file_2)\n",
    "process_log_file(human_log_file_3)\n",
    "process_log_file(human_log_file_4)\n",
    "process_log_file(human_log_file_5)\n",
    "\n",
    "# ----------------------\n",
    "# Compute derived features.\n",
    "# ----------------------\n",
    "SEQUENTIAL_THRESHOLD = 2.0  # seconds\n",
    "\n",
    "for session_id, feat in session_features.items():\n",
    "    # Image Requests Percent.\n",
    "    feat['image_requests_percent'] = (feat['image_requests'] / feat['total_requests'] * 100\n",
    "                                        if feat['total_requests'] > 0 else 0)\n",
    "    # HTML-to-Image Ratio.\n",
    "    feat['html_to_image_ratio'] = (feat['html_requests'] / feat['image_requests']\n",
    "                                    if feat['image_requests'] > 0 else feat['html_requests'])\n",
    "    # Depth Standard Deviation.\n",
    "    feat['depth_std'] = np.std(feat['depths']) if feat['depths'] else 0\n",
    "    # Max Requests Per Page.\n",
    "    feat['max_requests_per_page'] = max(feat['page_requests'].values()) if feat['page_requests'] else 0\n",
    "    \n",
    "    # Timing-based features.\n",
    "    timestamps = sorted(feat['timestamps'])\n",
    "    if timestamps:\n",
    "        session_duration = (timestamps[-1] - timestamps[0]).total_seconds()\n",
    "    else:\n",
    "        session_duration = 0\n",
    "    feat['session_duration'] = session_duration\n",
    "    if len(timestamps) > 1:\n",
    "        diffs = [(timestamps[i+1] - timestamps[i]).total_seconds() for i in range(len(timestamps)-1)]\n",
    "        feat['inter_request_avg'] = np.mean(diffs)\n",
    "        sequential_count = sum(1 for diff in diffs if diff < SEQUENTIAL_THRESHOLD)\n",
    "        feat['sequential_req_percent'] = (sequential_count / len(diffs)) * 100\n",
    "    else:\n",
    "        feat['inter_request_avg'] = 0\n",
    "        feat['sequential_req_percent'] = 0\n",
    "    # Browsing Speed.\n",
    "    feat['browsing_speed'] = (feat['total_requests'] / session_duration\n",
    "                              if session_duration > 0 else feat['total_requests'])\n",
    "\n",
    "# ----------------------\n",
    "# Convert session_features to DataFrame.\n",
    "# ----------------------\n",
    "df_features = pd.DataFrame.from_dict(session_features, orient='index')\n",
    "df_features.index.name = 'session_id'\n",
    "df_features.reset_index(inplace=True)\n",
    "\n",
    "def read_annotation(file_path):\n",
    "    \"\"\"Read an annotation file with session_id and label into a DataFrame.\"\"\"\n",
    "    annotations = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                session_id, label = parts\n",
    "                annotations.append({'session_id': session_id.strip(), 'label': label.strip().lower()})\n",
    "    return pd.DataFrame(annotations)\n",
    "\n",
    "df_train_annot = read_annotation(train_annotation_file)\n",
    "df_test_annot  = read_annotation(test_annotation_file)\n",
    "\n",
    "# ----------------------\n",
    "# Merge features with annotations using concat.\n",
    "# ----------------------\n",
    "df_features.set_index('session_id', inplace=True)\n",
    "df_train_annot.set_index('session_id', inplace=True)\n",
    "df_test_annot.set_index('session_id', inplace=True)\n",
    "df_train = pd.concat([df_features, df_train_annot], axis=1, join='inner').reset_index()\n",
    "df_test  = pd.concat([df_features, df_test_annot], axis=1, join='inner').reset_index()\n",
    "\n",
    "# Map labels: 'human' -> 0, 'moderate_bot'/'bot'/'advanced_bot' -> 1.\n",
    "label_map = {'human': 0, 'moderate_bot': 1, 'bot': 1, 'advanced_bot': 1}\n",
    "df_train['label'] = df_train['label'].map(label_map)\n",
    "df_test['label']  = df_test['label'].map(label_map)\n",
    "\n",
    "print(\"Training distribution:\")\n",
    "print(\"Human:\", df_train[df_train['label'] == 0].shape[0])\n",
    "print(\"Bot:\", df_train[df_train['label'] == 1].shape[0])\n",
    "\n",
    "# ----------------------\n",
    "# Define feature columns and normalize inputs.\n",
    "# ----------------------\n",
    "feature_cols = [\n",
    "    'total_requests', \n",
    "    'total_bytes', \n",
    "    'GET', \n",
    "    'POST', \n",
    "    'http_3xx', \n",
    "    'http_4xx', \n",
    "    'image_requests_percent',\n",
    "    'html_to_image_ratio',\n",
    "    'depth_std',\n",
    "    'max_requests_per_page',\n",
    "    'sequential_req_percent',\n",
    "    'browsing_speed',\n",
    "    'session_duration',\n",
    "    'inter_request_avg'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['label']\n",
    "X_test  = df_test[feature_cols]\n",
    "y_test  = df_test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# Train multiple classifiers, including TabNet.\n",
    "# ----------------------\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Add TabNet as an additional classifier.\n",
    "classifiers[\"TabNet\"] = TabNetClassifier(\n",
    "    n_d=8, n_a=8, n_steps=3, gamma=1.5,\n",
    "    lambda_sparse=1e-3,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax',  # alternative: \"sparsemax\"\n",
    "    verbose=0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    if name == \"TabNet\":\n",
    "        clf.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            eval_set=[(X_test_scaled, y_test)],\n",
    "            eval_name=['test'],\n",
    "            eval_metric=['auc'],\n",
    "            max_epochs=100,\n",
    "            patience=10,\n",
    "            batch_size=2,\n",
    "            virtual_batch_size=128\n",
    "        )\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        y_prob = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix for each classifier.\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Human\", \"Bot\"], yticklabels=[\"Human\", \"Bot\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1_with_advance_bot/{name.replace(' ', '_').lower()}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot a bar chart comparing classifier metrics.\n",
    "# ----------------------\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "metric_values = {metric: [results[clf][metric] for clf in results] for metric in metrics}\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.2\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, metric_values[metric], width, label=metric.title())\n",
    "plt.xticks(x + width*1.5, list(classifiers.keys()))\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Classifier Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/classifier_performance_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Plot ROC curves for classifiers that support probability estimates.\n",
    "# ----------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "for name in classifiers:\n",
    "    if results[name][\"y_prob\"] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, results[name][\"y_prob\"])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/roc_curve_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------\n",
    "# Additional Graphs on Feature Distributions and Scatter Plots.\n",
    "# ----------------------\n",
    "features_to_plot = ['total_requests', 'session_duration', 'browsing_speed', 'inter_request_avg']\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df_train[feature], bins=20, kde=True)\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.title(f\"Distribution of {feature.replace('_', ' ').title()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"phase_1_with_advance_bot/{feature}_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=\"session_duration\", y=\"browsing_speed\", hue=\"label\", data=df_train, palette=\"Set1\")\n",
    "plt.xlabel(\"Session Duration (s)\")\n",
    "plt.ylabel(\"Browsing Speed (req/s)\")\n",
    "plt.title(\"Session Duration vs. Browsing Speed\")\n",
    "plt.legend(title=\"Label\", labels=[\"Human\", \"Bot\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"phase_1_with_advance_bot/session_duration_vs_browsing_speed.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"All graphs have been saved as PNG files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
